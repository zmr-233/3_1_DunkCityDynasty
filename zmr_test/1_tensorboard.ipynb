{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.utils.tensorboardæ¨¡å—\n",
    "\n",
    "ä¸»è¦ä½¿ç”¨ **@O `torch.utils.tensorboard.writer`** å¯¹è±¡è¿›è¡Œæ“ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”µ`SummaryWriter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ”¹`SummaryWriter(log_dir = Noneï¼Œ comment = ''ï¼Œ purge_step = Noneï¼Œ max_queue = 10ï¼Œ flush_secs = 120ï¼Œ filename_suffix = '')`\n",
    "\n",
    "- **_@param `log_dir (str)`_**<br>\n",
    "ä¿å­˜ç›®å½•çš„ä½ç½®ã€‚é»˜è®¤ä¸º`runs/CURRENT_DATETIME_HOSTNAME`ï¼Œæ¯æ¬¡è¿è¡Œåéƒ½ä¼šæ›´æ”¹ã€‚ä½¿ç”¨åˆ†å±‚çš„æ–‡ä»¶å¤¹ç»“æ„ï¼Œä¾¿äºè½»æ¾æ¯”è¾ƒä¸åŒçš„è¿è¡Œã€‚ä¾‹å¦‚ï¼Œä¸ºæ¯ä¸€ä¸ªæ–°å®éªŒä¼ å…¥ â€˜runs/exp1â€™, â€˜runs/exp2â€™ ç­‰ï¼Œä»¥ä¾¿åœ¨å®ƒä»¬ä¹‹é—´è¿›è¡Œæ¯”è¾ƒ\n",
    "\n",
    "- _@param `comment (str)`_<br>\n",
    "æ·»åŠ åˆ°é»˜è®¤ log_dir çš„æ³¨é‡Šåç¼€ã€‚å¦‚æœå·²åˆ†é… log_dirï¼Œåˆ™æ­¤å‚æ•°æ— æ•ˆ\n",
    "\n",
    "- **_@param `purge_step (int)`_**<br>\n",
    "å½“æ—¥å¿—åœ¨æ­¥éª¤T+X å´©æºƒå¹¶åœ¨æ­¥éª¤T é‡å¯æ—¶ï¼Œä»»ä½• global_step å¤§äºæˆ–ç­‰äºT çš„äº‹ä»¶éƒ½å°†è¢«æ¸…é™¤ï¼Œå¹¶ä» TensorBoard ä¸­éšè—\n",
    "\n",
    "- _@param `max_queue (int)`_<br>\n",
    "åœ¨å…¶ä¸­ä¸€ä¸ªâ€˜addâ€™è°ƒç”¨å¼ºåˆ¶å°†äº‹ä»¶å’Œæ‘˜è¦åˆ·æ–°åˆ°ç£ç›˜ä¹‹å‰ï¼Œç­‰å¾…å¤„ç†çš„äº‹ä»¶å’Œæ‘˜è¦çš„é˜Ÿåˆ—å¤§å°\n",
    "    > ç”¨äºæ‰¹é‡å†™å…¥ç£ç›˜ï¼Œå½“è¾¾åˆ°max_queueæ—¶æ‰ä¼šå†™å…¥ç£ç›˜ï¼Œæ‰€ä»¥æœ‰æ—¶å€™ä¸å¼ºåˆ¶è°ƒç”¨`writer.close()`å°±ä¼šå¯¼è‡´æ•°æ®ä¸è¢«å†™å…¥ç£ç›˜\n",
    "\n",
    "- _@param `flush_secs (int)`_<br>\n",
    "æ¯éš”å¤šå°‘ç§’åˆ·æ–°ç­‰å¾…å¤„ç†çš„äº‹ä»¶å’Œæ‘˜è¦åˆ°ç£ç›˜ã€‚é»˜è®¤ä¸ºæ¯ä¸¤åˆ†é’Ÿä¸€æ¬¡\n",
    "\n",
    "- _@param `filename_suffix (str)`_<br>\n",
    "æ·»åŠ åˆ° log_dir ç›®å½•ä¸­æ‰€æœ‰äº‹ä»¶æ–‡ä»¶åçš„åç¼€\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹ï¼š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# create a summary writer with automatically generated folder name.\n",
    "writer = SummaryWriter()\n",
    "# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n",
    "\n",
    "# create a summary writer using the specified folder name.\n",
    "writer = SummaryWriter(\"my_experiment\")\n",
    "# folder location: my_experiment\n",
    "\n",
    "# create a summary writer with comment appended.\n",
    "writer = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n",
    "# folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_scalar(tag, scalar_value, global_step=None, walltime=None, new_style=False, double_precision=False)`\n",
    "\n",
    "- **_@param `tag (str)`_**<br>\n",
    "æ•°æ®æ ‡è¯†ç¬¦(æ ‡ç­¾)\n",
    "\n",
    "- **_@param `scalar_value`_**<br>\n",
    "è¦ä¿å­˜çš„å€¼\n",
    "\n",
    "- **_@param `global_step(int)`_**<br>\n",
    "è¦è®°å½•çš„å…¨å±€æ­¥éª¤å€¼\n",
    "\n",
    "- **_@param `walltime(float)`_**<br>\n",
    "å¯é€‰çš„è¦†ç›–é»˜è®¤çš„ walltimeï¼ˆtime.time()ï¼‰å€¼ï¼Œå³å½“å‰æ—¶é—´ï¼Œå¯ä»¥æ‰‹åŠ¨è®¾ç½®æ—¶é—´æˆ³ï¼Œå³äº‹ä»¶å‘ç”Ÿåçš„ç»è¿‡çš„ç§’æ•°\n",
    "\n",
    "- **_@param `new_style (boolean)`_**<br>\n",
    "æ˜¯å¦ä½¿ç”¨æ–°æ ·å¼(é»˜è®¤True)\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹ï¼š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "x = range(100)\n",
    "for i in x:\n",
    "    writer.add_scalar('y=2x', i * 2, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None)`\n",
    "ç”¨äºæ‰¹é‡æ·»åŠ æ•°æ®\n",
    "- **_@param `main_tag (str)`_**<br>\n",
    "çˆ¶tagåç§°\n",
    "\n",
    "- **_@param `tag_scalar_dict (dict)`_**<br>\n",
    "key-valueé”®å€¼å¯¹ç»„æˆå­æ ‡ç­¾\n",
    "\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "r = 5\n",
    "for i in range(100):\n",
    "    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n",
    "                                    'xcosx':i*np.cos(i/r),\n",
    "                                    'tanx': np.tan(i/r)}, i)\n",
    "writer.close()\n",
    "# This call adds three values to the same scalar plot with the tag\n",
    "# 'run_14h' in TensorBoard's scalar section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None)`\n",
    "å‘æ‘˜è¦ä¸­æ·»åŠ ä¸€ä¸ªç›´æ–¹å›¾\n",
    "- **_@param `tag (str)`_**<br>\n",
    "- **_@param `values`_**<br>\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `bins (str)`_**<br>\n",
    "ç›´æ–¹å›¾ç±»å‹ï¼Œé€šå¸¸æœ‰å¦‚ä¸‹ç±»å‹ {â€˜tensorflowâ€™,â€™autoâ€™, â€˜fdâ€™, â€¦}ã€‚è¿™å†³å®šäº†å¦‚ä½•åˆ¶ä½œåˆ†ç®±å­ã€‚å¯ä»¥åœ¨ä»¥ä¸‹é“¾æ¥ä¸­æ‰¾åˆ°å…¶ä»–é€‰é¡¹[ç›´æ–¹å›¾ç±»å‹](https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html)\n",
    "\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "- **_@param ``_**<br>\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "writer = SummaryWriter()\n",
    "for i in range(10):\n",
    "    x = np.random.random(1000)\n",
    "    writer.add_histogram('distribution centers', x + i, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')`\n",
    "æ·»åŠ å›¾ç‰‡\n",
    "\n",
    "- **_@param `tag (str)`_**<br>\n",
    "- **_@param `img_tensor`_**<br>\n",
    "å›¾åƒå¼ é‡ï¼Œé€šå¸¸æ˜¯$(3,H,W)$ï¼Œå…¶ä¸­3æ˜¯RGBä¸‰ä¸ªé¢œè‰²ï¼Œå½“ç„¶ä¹Ÿæ¥å—(1,H,W)æˆ–è€…(H,W,3)ï¼Œäºæ˜¯å°±éœ€è¦æŒ‡å®šç±»å‹`CHW,HWC,HW`\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "- **_@param `dataformats (str)`_**<br>\n",
    "å›¾åƒå¼ é‡ç±»å‹ï¼Œé€šå¸¸æ˜¯`CHW, HWC, HW, WH`\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "img = np.zeros((3, 100, 100))\n",
    "img[0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "\n",
    "img_HWC = np.zeros((100, 100, 3))\n",
    "img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_image('my_image', img, 0)\n",
    "\n",
    "# If you have non-default dimension setting, set the dataformats argument.\n",
    "writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_images(tag, img_tensor, global_step=None, walltime=None, dataformats='NCHW')`\n",
    "æ‰¹é‡æ·»åŠ å›¾åƒå¼ é‡\n",
    "- **_@param `tag (str)`_**<br>\n",
    "- **_@param `img_tensor `_**<br>\n",
    "è¿™é‡Œçš„å›¾åƒå¼ é‡é»˜è®¤ä¸º$(N,3,H,W)$\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "img_batch = np.zeros((16, 3, 100, 100))\n",
    "for i in range(16):\n",
    "    img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n",
    "    img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_images('my_image_batch', img_batch, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_figure(tag, figure, global_step=None, close=True, walltime=None)`\n",
    "ç”¨äºæ·»åŠ matplotlib figureå¯¹è±¡ï¼Œè¦ç”¨æ—¶å€™å†è®° \n",
    "[å®˜æ–¹æ‰‹å†Œ](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_figure)\n",
    "\n",
    "- **_@param ``_**<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_video(tag, vid_tensor, global_step=None, fps=4, walltime=None)`\n",
    "ç”¨äºæ·»åŠ è§†é¢‘ï¼Œè¦ç”¨æ—¶å€™å†è®° \n",
    "[å®˜æ–¹æ‰‹å†Œ](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_video)\n",
    "\n",
    "- **_@param ``_**<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_video(tag, vid_tensor, global_step=None, fps=4, walltime=None)`\n",
    "ç”¨äºæ·»åŠ éŸ³é¢‘ï¼Œè¦ç”¨æ—¶å€™å†è®° \n",
    "[å®˜æ–¹æ‰‹å†Œ](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_video)\n",
    "\n",
    "- **_@param ``_**<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_text(tag, text_string, global_step=None, walltime=None)`\n",
    "ç”¨äºæ·»åŠ æ–‡æœ¬ä¿¡æ¯\n",
    "- **_@param `tag (str)`_**<br>\n",
    "- **_@param `text_string (str)`_**<br>\n",
    "å®é™…ä¿å­˜çš„Stringå­—ç¬¦ä¸²\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "```python\n",
    "writer.add_text('lstm', 'This is an lstm', 0)\n",
    "writer.add_text('rnn', 'This is an rnn', 10)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)`\n",
    "\n",
    "æ·»åŠ åµŒå…¥å¼æŠ•å½±ä»ªæ•°æ®ï¼Œç”¨äºå¯è§†åŒ–é«˜ç»´æ•°æ®åœ¨ä½ç»´ç©ºé—´ä¸­çš„è¡¨ç¤º(å°†ç‰¹å¾å‘é‡æ˜ å°„åˆ°ä¸‰ç»´ä¸­)\n",
    "- **_@param `mat (torch.Tensor or numpy.ndarray)`_**<br>\n",
    "    ä¸€ä¸ªçŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸€è¡Œéƒ½æ˜¯æ•°æ®ç‚¹çš„ç‰¹å¾å‘é‡\n",
    "    > mat.shapeåº”è¯¥ä¸º$(N,D)$ï¼Œå…¶ä¸­Nä¸ºä¸ªæ•°ï¼ŒDä¸ºç»´åº¦\n",
    "\n",
    "- **_@param `metadata (list)`_**<br>\n",
    "    ä¸€ä¸ªæ ‡ç­¾åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ éƒ½ä¼šè¢«è½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "\n",
    "- **_@param `label_img`_**<br>\n",
    "    ä¸æ¯ä¸ªæ•°æ®ç‚¹å¯¹åº”çš„å›¾åƒ\n",
    "    > label_img:$(N,C,H,W)$ï¼Œæ³¨æ„å›¾åƒæ˜¯å¯é€‰å‚æ•°ï¼Œå¯æœ‰å¯æ— å› ä¸ºè¿™ä¸ªåªæ˜¯å¯¹åº”äºmatç‰¹å¾çŸ©é˜µçš„\"æ ‡ç­¾\"\n",
    "\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "    è¦è®°å½•çš„å…¨å±€æ­¥éª¤å€¼\n",
    "- **_@param `tag (str)`_**<br>\n",
    "    åµŒå…¥çš„åç§°\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "å¯ä»¥çœ‹åˆ°å›¾åƒæœ‰ååˆ†ç¾ä¸½çš„ä¸‰ç»´ç»“æ„ï¼š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "import torch\n",
    "meta = []\n",
    "while len(meta)<100:\n",
    "    meta = meta+keyword.kwlist # get some strings\n",
    "meta = meta[:100]\n",
    "\n",
    "for i, v in enumerate(meta):\n",
    "    meta[i] = v+str(i)\n",
    "\n",
    "label_img = torch.rand(100, 3, 10, 32)\n",
    "for i in range(100):\n",
    "    label_img[i]*=i/100.0\n",
    "\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\n",
    "writer.add_embedding(torch.randn(100, 5), label_img=label_img)\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_pr_curve(tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None)`\n",
    "\n",
    "ç”¨äºæ·»åŠ ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„å‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°å…è®¸ä½ è·Ÿè¸ªæ¨¡å‹åœ¨ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼Œä»è€Œæ›´å¥½åœ°è¯„ä¼°å’Œè°ƒæ•´æ¨¡å‹:\n",
    "- **_@param `tag (str)`_**<br>\n",
    "- **_@param `labels (torch.Tensor, numpy.ndarray, or string/blobname) `_**<br>\n",
    "çœŸå®çš„æ ‡ç­¾ï¼Œåº”è¯¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º [batch_size] çš„æ•°ç»„ï¼Œå…¶ä¸­åŒ…å«å€¼ 0 æˆ– 1\n",
    "\n",
    "- **_@param `predictions (torch.Tensor, numpy.ndarray, or string/blobname)`_**<br>\n",
    "æ¨¡å‹çš„é¢„æµ‹ç½®ä¿¡åº¦ï¼Œåº”è¯¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º [batch_size] çš„æ•°ç»„ï¼Œå…¶ä¸­çš„å€¼åœ¨ 0 å’Œ 1 ä¹‹é—´\n",
    "\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `num_thresholds (int)`_**<br>\n",
    " è¦ä½¿ç”¨çš„é˜ˆå€¼æ•°é‡ã€‚é»˜è®¤æ˜¯ 127\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é™„å½•ï¼šç²¾ç¡®ç‡-å¬å›ç‡ & ç½®ä¿¡åŸŸ\n",
    "1. **ç²¾ç¡®ç‡-å¬å›ç‡ (Precision-Recall)**\n",
    "\n",
    "- **ç²¾ç¡®ç‡ (Precision)**: åœ¨æ‰€æœ‰è¢«æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ ·æœ¬ä¸­ï¼ŒçœŸæ­£æ˜¯æ­£ä¾‹çš„æ¯”ä¾‹ã€‚\n",
    "  $$\\text{ç²¾ç¡®ç‡} = \\frac{\\text{çœŸæ­£ä¾‹ (TP)}}{\\text{çœŸæ­£ä¾‹ (TP) + å‡æ­£ä¾‹ (FP)}}$$\n",
    "\n",
    "- **å¬å›ç‡ (Recall)**: åœ¨æ‰€æœ‰çœŸæ­£çš„æ­£ä¾‹æ ·æœ¬ä¸­ï¼Œè¢«æ¨¡å‹æ­£ç¡®é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹ã€‚\n",
    "  $$\\text{å¬å›ç‡} = \\frac{\\text{çœŸæ­£ä¾‹ (TP)}}{\\text{çœŸæ­£ä¾‹ (TP) + å‡è´Ÿä¾‹ (FN)}}$$\n",
    "\n",
    "è¿™ä¸¤ä¸ªæŒ‡æ ‡é€šå¸¸ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ­£ä¾‹é¢„æµ‹ä¸Šçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ç±»åˆ«ä¸å¹³è¡¡çš„æƒ…å†µä¸‹\n",
    "\n",
    "2. **å½“ä½ æƒ³è¦å¯¹æ¯”æ¨¡å‹åœ¨ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„æ€§èƒ½æ—¶**\n",
    "åœ¨å¾ˆå¤šæœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œç‰¹åˆ«æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œæ¨¡å‹ä¸ºæ¯ä¸ªæ ·æœ¬è¾“å‡ºä¸€ä¸ªç½®ä¿¡åº¦åˆ†æ•°ï¼Œè¿™ä¸ªåˆ†æ•°è¡¨ç¤ºè¯¥æ ·æœ¬å±äºæŸä¸€ç±»çš„æ¦‚ç‡ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬ä¼šè®¾ç½®ä¸€ä¸ªé˜ˆå€¼ï¼ˆå¦‚0.5ï¼‰ï¼Œå½“ç½®ä¿¡åº¦åˆ†æ•°é«˜äºè¿™ä¸ªé˜ˆå€¼æ—¶ï¼Œæˆ‘ä»¬åˆ¤æ–­æ ·æœ¬ä¸ºæ­£ä¾‹ï¼Œå¦åˆ™ä¸ºè´Ÿä¾‹ã€‚\n",
    "\n",
    "ä½†æ˜¯ï¼Œè¿™ä¸ªé˜ˆå€¼æ˜¯å¯ä»¥è°ƒæ•´çš„ã€‚æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æ›´é«˜çš„ç²¾ç¡®ç‡æˆ–å¬å›ç‡ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬å¸Œæœ›å°½é‡é¿å…å‡é˜³æ€§æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæé«˜é˜ˆå€¼ä»¥è·å¾—æ›´é«˜çš„ç²¾ç¡®ç‡ï¼Œä½†è¿™å¯èƒ½ä¼šç‰ºç‰²å¬å›ç‡\n",
    "\n",
    "é€šè¿‡ç»˜åˆ¶ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°çœ‹åˆ°æ¨¡å‹åœ¨ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„æ€§èƒ½ï¼Œä»è€Œå¸®åŠ©æˆ‘ä»¬é€‰æ‹©æœ€ä½³çš„é˜ˆå€¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "labels = np.random.randint(2, size=100)  # binary label\n",
    "predictions = np.random.rand(100)\n",
    "writer = SummaryWriter()\n",
    "writer.add_pr_curve('pr_curve', labels, predictions, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_custom_scalars(layout)`\n",
    "åˆ›å»ºä¸€ä¸ªç‰¹æ®Šçš„å›¾è¡¨ï¼Œé€šè¿‡åœ¨â€œæ ‡é‡â€ä¸­æ”¶é›†å›¾è¡¨æ ‡ç­¾ã€‚\n",
    "> æ³¨æ„ï¼Œæ¯ä¸ªSummaryWriter()å¯¹è±¡åªèƒ½è°ƒç”¨æ­¤å‡½æ•°ä¸€æ¬¡--å› ä¸ºå®ƒåªä¸º tensorboard æä¾›å…ƒæ•°æ®!!**æ‰€ä»¥è¯¥å‡½æ•°å¯ä»¥åœ¨è®­ç»ƒå¾ªç¯ä¹‹å‰æˆ–ä¹‹åè°ƒç”¨**\n",
    "\n",
    "- **_@param `layout (dict) `_**<br>\n",
    "1. {ç±»åˆ«åç§°: å›¾è¡¨}å…¶ä¸­å›¾è¡¨ä¹Ÿæ˜¯ä¸€ä¸ªå­—å…¸:å¦‚ä¸Šå°±æœ‰ä¸¤ä¸ªç±»åˆ«(å°æ¹¾&ç¾å›½)ï¼Œä¸€å…±ä¸‰ä¸ªå›¾è¡¨(å°è‚¡,é“ç¼æ–¯,çº³æ–¯è¾¾å…‹)\n",
    "2. {å›¾è¡¨åç§°: [å±æ€§åˆ—è¡¨]}å±æ€§åˆ—è¡¨:<br>\n",
    "ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å›¾è¡¨çš„ç±»å‹ï¼ˆMultilineæˆ–Marginä¹‹ä¸€ï¼‰<br>\n",
    "ç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«ä½ åœ¨add_scalarå‡½æ•°ä¸­ä½¿ç”¨çš„æ ‡ç­¾ï¼Œè¿™äº›æ ‡ç­¾å°†è¢«æ”¶é›†åˆ°æ–°å›¾è¡¨ä¸­\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "> æ³¨æ„add_custom_scalarsæ˜¯é’ˆå¯¹å·²æœ‰æ—¥å¿—è¿›è¡Œçš„åˆ†æï¼Œç›¸å½“äºå°±æä¾›äº†ä¸€ä¸ªæ¯”è¾ƒçš„æ¡†æ¶ï¼Œä»…æ­¤è€Œå·²\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n",
    "\n",
    "layout = {\n",
    "    'Loss': {\n",
    "        'Train vs. Test': ['Multiline', ['Loss/train', 'Loss/test']]\n",
    "    },\n",
    "    'Accuracy': {\n",
    "        'Train vs. Test': ['Multiline', ['Accuracy/train', 'Accuracy/test']]\n",
    "    }\n",
    "}\n",
    "\n",
    "writer.add_custom_scalars(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "writer = SummaryWriter()\n",
    "\n",
    "layout = {'å°æ¹¾':{'å°è‚¡':['Multiline',['å°è‚¡/0050', 'å°è‚¡/2330']]},\n",
    "          'ç¾å›½':{'é“ç¼æ–¯':['Margin',   ['é“ç¼æ–¯/aaa', 'é“ç¼æ–¯/bbb', 'é“ç¼æ–¯/ccc']],\n",
    "                 'çº³æ–¯è¾¾å…‹':['Margin',   ['çº³æ–¯è¾¾å…‹/aaa', 'çº³æ–¯è¾¾å…‹/bbb', 'çº³æ–¯è¾¾å…‹/ccc']]}}\n",
    "\n",
    "writer.add_custom_scalars(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_mesh(tag, vertices, colors=None, faces=None, config_dict=None, global_step=None, walltime=None)`\n",
    "(å›¾å½¢å­¦/ä¸‰ç»´æ¸²æŸ“)å°†ç½‘æ ¼æˆ–3Dç‚¹äº‘æ·»åŠ åˆ°TensorBoardã€‚è¿™ä¸ªå¯è§†åŒ–åŸºäºThree.jsï¼Œæ‰€ä»¥å®ƒå…è®¸ç”¨æˆ·ä¸æ¸²æŸ“çš„å¯¹è±¡è¿›è¡Œäº¤äº’ã€‚é™¤äº†åŸºæœ¬çš„å®šä¹‰ï¼Œå¦‚é¡¶ç‚¹ã€é¢ä¹‹å¤–ï¼Œç”¨æˆ·è¿˜å¯ä»¥æä¾›ç›¸æœºå‚æ•°ã€å…‰ç…§æ¡ä»¶ç­‰\n",
    "\n",
    "[è¯¦ç»†ä¿¡æ¯](https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene)\n",
    "- **_@param `tag (str)`_**<br>\n",
    "- **_@param `vertices (torch.Tensor)`_**<br>\n",
    "é¡¶ç‚¹çš„3Dåæ ‡åˆ—è¡¨\n",
    "- **_@param `colors (torch.Tensor)`_**<br>\n",
    "æ¯ä¸ªé¡¶ç‚¹çš„é¢œè‰²\n",
    "- **_@param `faces (torch.Tensor) `_**<br>\n",
    "æ¯ä¸ªä¸‰è§’å½¢å†…çš„é¡¶ç‚¹ç´¢å¼•(å¯é€‰)\n",
    "- **_@param `config_dict`_**<br>\n",
    "å¸¦æœ‰ThreeJSç±»åå’Œé…ç½®çš„å­—å…¸\n",
    "- **_@param `global_step (int)`_**<br>\n",
    "- **_@param `walltime (float)`_**<br>\n",
    "\n",
    "shape:\n",
    "- **vertices**: $(B, N, 3)$ã€‚ $(æ‰¹æ¬¡å¤§å°, é¡¶ç‚¹æ•°é‡, é€šé“æ•°)$\n",
    "- **colors**: $(B, N, 3)$ã€‚å¯¹äº uint8 ç±»å‹ï¼Œå€¼åº”è¯¥åœ¨ [0,255] èŒƒå›´å†…ï¼›å¯¹äº float ç±»å‹ï¼Œå€¼åº”è¯¥åœ¨ [0,1] èŒƒå›´å†…\n",
    "- **faces**: $(B, N, 3)$ã€‚å¯¹äº uint8 ç±»å‹ï¼Œå€¼åº”è¯¥åœ¨ [0, é¡¶ç‚¹æ•°é‡] èŒƒå›´å†…\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "vertices_tensor = torch.as_tensor([\n",
    "    [1, 1, 1],\n",
    "    [-1, -1, 1],\n",
    "    [1, -1, -1],\n",
    "    [-1, 1, -1],\n",
    "], dtype=torch.float).unsqueeze(0)\n",
    "colors_tensor = torch.as_tensor([\n",
    "    [255, 0, 0],\n",
    "    [0, 255, 0],\n",
    "    [0, 0, 255],\n",
    "    [255, 0, 255],\n",
    "], dtype=torch.int).unsqueeze(0)\n",
    "faces_tensor = torch.as_tensor([\n",
    "    [0, 2, 3],\n",
    "    [0, 3, 1],\n",
    "    [0, 1, 2],\n",
    "    [1, 3, 2],\n",
    "], dtype=torch.int).unsqueeze(0)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ”º`add_hparams(hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None)`\n",
    "\n",
    "æ·»åŠ ä¸€ç»„è¶…å‚æ•°æ¯”è¾ƒ\n",
    "\n",
    "- **_@param `hparam_dict (dict)`_**<br>\n",
    "å­—å…¸ä¸­çš„æ¯ä¸€ä¸ªé”®å€¼å¯¹æ˜¯è¶…å‚æ•°çš„åç§°åŠå…¶å¯¹åº”çš„å€¼ã€‚è¯¥å€¼çš„ç±»å‹å¯ä»¥æ˜¯boolã€stringã€floatã€intæˆ–Noneä¹‹ä¸€\n",
    "\n",
    "- **_@param `metric_dict (dict)`_**<br>\n",
    "å­—å…¸ä¸­çš„æ¯ä¸€ä¸ªé”®å€¼å¯¹æ˜¯æŒ‡æ ‡çš„åç§°åŠå…¶å¯¹åº”çš„å€¼ã€‚æ³¨æ„ï¼Œè¿™é‡Œä½¿ç”¨çš„é”®åœ¨tensorboardè®°å½•ä¸­åº”è¯¥æ˜¯å”¯ä¸€çš„ã€‚å¦åˆ™ï¼Œæ‚¨é€šè¿‡add_scalaræ·»åŠ çš„å€¼å°†ä¼šåœ¨hparamæ’ä»¶ä¸­æ˜¾ç¤ºã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ä¸å¸Œæœ›çš„\n",
    "\n",
    "- **_@param `hparam_domain_discrete`_**<br>\n",
    "ï¼ˆå¯é€‰[Dict[str, List[Any]]]ï¼‰ä¸€ä¸ªåŒ…å«è¶…å‚æ•°åç§°å’Œå®ƒä»¬å¯ä»¥æŒæœ‰çš„æ‰€æœ‰ç¦»æ•£å€¼çš„å­—å…¸\n",
    "\n",
    "- **_@param `run_name (str)`_**<br>\n",
    "è¿è¡Œçš„åç§°ï¼Œä½œä¸ºæ—¥å¿—ç›®å½•çš„ä¸€éƒ¨åˆ†åŒ…å«åœ¨å†…ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨å½“å‰çš„æ—¶é—´æˆ³\n",
    "\n",
    "ä½¿ç”¨ä¸¾ä¾‹:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "with SummaryWriter() as w:\n",
    "    for i in range(5):\n",
    "        w.add_hparams({'lr': 0.1*i, 'bsize': i}, #è¿™é‡Œlr / bsizeæ˜¯è¶…å‚æ•°\n",
    "                      {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4_DCD380",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
