#import sys,os
#import gymnasium as gym
#import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

#é™„å±å·¥å…·====================================================================================================
#a.æ¿€æ´»å‡½æ•°é€‰æ‹©å·¥å…· ----------------------------------------------------------------------------------------------------
def get_activation_func(name, hidden_dim):
    """
    'relu'
    'tanh'
    'leaky_relu'
    'elu'
    'prelu'
    :param name:
    :return:
    """
    if name == "relu":
        return nn.ReLU(inplace=True)
    elif name == "tanh":
        return nn.Tanh()
    elif name == "leaky_relu":
        return nn.LeakyReLU(negative_slope=0.01, inplace=True)
    elif name == "elu":
        return nn.ELU(alpha=1., inplace=True)
    elif name == 'prelu':
        return nn.PReLU(num_parameters=hidden_dim, init=0.25)
#b.åŠ¨ä½œåµŒå…¥å±‚-----------------------------------------------------------------------------------------
class ActionEmbedding(nn.Module):
    def __init__(self, embedding_dim):
        super().__init__()
        num_actions =  52
        self.embedding = nn.Embedding(num_actions, embedding_dim)

    def forward(self, action_indices):
        return self.embedding(action_indices)
#c.å¤šå¤´åˆå¹¶å±‚-----------------------------------------------------------------------------------------
class Merger_1(nn.Module):
    def __init__(self, head, fea_dim):
        '''åˆå¹¶[batch_size, n_heads, fea_dim]->[batch_size, fea_dim]
        
        '''
        super().__init__()
        self.head = head
        self.fea_dim = fea_dim
        if head > 1:
            self.weight = nn.Parameter(torch.Tensor(1, head, fea_dim).fill_(1.))
            self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        '''

        :param x: [bs, n_head, fea_dim]
        :return: [bs, fea_dim]
        '''
        if self.head > 1:
            batch_size = x.size(0)
            weight = self.weight.expand(batch_size, -1, -1)
            weighted_x = self.softmax(weight) * x
            return torch.sum(weighted_x, dim=1)
        else:
            return x.squeeze(1)

class Merger_2(nn.Module):
    def __init__(self, head, fea_dim):
        '''åˆå¹¶ [batch_size, 1, n_heads, fea_dim]->[batch_size, fea_dim]
        
        '''
        super().__init__()
        self.head = head
        self.fea_dim = fea_dim
        if head > 1:
            self.weight = nn.Parameter(torch.Tensor(1, head, fea_dim).fill_(1.))
            self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        """
        :param x: [bs, n_head, fea_dim]
        :return: [bs, fea_dim]
        """
        #BUG:
        if self.head > 1:
            batch_size = x.size(0)
            weight = self.weight.expand(batch_size, -1, -1)
            #BUG:ğŸ”µå°ä¿®æ”¹ï¼Œxçš„viewçš„ç»´åº¦
            #return torch.sum(self.softmax(weight) * x.view(batch_size, self.head, -1), dim=1)
            return torch.sum(self.softmax(weight) * x.view(batch_size, self.head, self.fea_dim), dim=1)
        else:
            return torch.squeeze(x, dim=1)
#c.çº¿æ€§å±‚&åµŒå…¥å±‚----------------------------------------------------------------------------------------
def embedding_layer(input_size, num_embeddings , embedding_dim, **kwargs):
    class EmbeddingLayer(nn.Module):
        def __init__(self, num_embeddings, embedding_dim, **kwargs):
            super(EmbeddingLayer, self).__init__()
            self.layer = nn.Embedding(num_embeddings=num_embeddings+1, embedding_dim=embedding_dim, **kwargs)
                                                    #ğŸ‘†æ³¨æ„æ½œåœ¨è¶Šç•Œé—®é¢˜num_embeddings+1
        def forward(self, x: torch.Tensor):
            return self.layer(x)
    layer = EmbeddingLayer(num_embeddings, embedding_dim, **kwargs)
    output_size = [None, embedding_dim]
    return layer, output_size
def linear_layer(input_size, layer_dim):
    input_dim = input_size[1]
    output_size = [None, layer_dim]
    layer = nn.Sequential(nn.Linear(input_dim, layer_dim), nn.ReLU())
    return layer, output_size
#d.AgentåµŒå…¥å±‚
class AgentEmbedding(nn.Module):
    '''åŸºç¡€æŸ¥è¡¨æ“ä½œ
    '''
    def __init__(self):
        super().__init__()
        self.agent_state_len = 73
        self.my_character_type_embed_layer, self.my_character_type_embed_layer_out_dim = embedding_layer([None], 100, 16)
        self.my_role_type_embed_layer, self.my_role_type_embed_layer_out_dim = embedding_layer([None], 8 ,8)
        self.my_buff_type_embed_layer, self.my_buff_type_embed_layer_out_dim = embedding_layer([None], 50, 6)
        #self.agent_state_dim = 16+8+6-3 + self.agent_state_len
        #---------------------------
        #self.agent_state_dim = -3 + self.agent_state_len #ğŸŸ -3å¯èƒ½å‡ºç°é—®é¢˜
        #ğŸ”µ++++++++++++++++++++++++++++æ­£ç¡®è®¡ç®—åµŒå…¥çš„æ€»ç»´åº¦
        self.agent_state_dim = self.my_character_type_embed_layer_out_dim[1] \
                               + self.my_role_type_embed_layer_out_dim[1] \
                               + self.my_buff_type_embed_layer_out_dim[1] \
                               + self.agent_state_len\
                               - 3 #è¿™ä¸ª-3ä»ä½•è€Œæ¥?
        #ğŸŸ -3åŸå› æ˜¯my_character_type/my_role_type/my_buff_typeæ˜¯å±äºself.agent_state_lençš„å…¶ä¸­ä¸‰ä¸ª
        #å½“æŠŠè¿™ä¸‰ä¸ªè½¬ä¸ºç‰¹å¾å‘é‡åï¼Œå°±è¦ä»åŸæ¥çš„self.agent_state_lenä¸­å‡å»3äº†ï¼Œè¿™å°±æ˜¯-3çš„åŸå› 
        #å› æ­¤ï¼Œå¦‚ä¸‹çš„forwardä¼ å…¥xçš„é•¿åº¦å°±æ˜¯73ï¼Œè€Œä¸å¤„ç†çš„éƒ¨åˆ†åˆ™æ˜¯ my_states = x[:,3:73].float()

    def forward(self,x):
        my_character_type = x[:, 0].long()
        my_role_type = x[:, 1].long()
        my_buff_type = x[:, 2].long()
        
        my_character_type = self.my_character_type_embed_layer(my_character_type)
        my_role_type = self.my_role_type_embed_layer(my_role_type)
        my_buff_type = self.my_buff_type_embed_layer(my_buff_type)
        
        my_states = x[:,3:].float()

        return my_character_type,my_role_type,my_buff_type,my_states

#====================================================================================================
#1.å®šä¹‰è¶…ç½‘ç»œ-----------------------------------------------------------------------------------------
class Hypernet(nn.Module):
    def __init__(self,input_dim,
                     hidden_dim,
                    main_input_dim,main_output_dim,
                    n_heads,
                    *,activation_func_name,
                    use_bias = False):
        '''æƒé‡ç”Ÿæˆç½‘ç»œ

        :param input_dim: ç‰¹å¾ä¿¡æ¯(HPNè¾“å…¥)
        :param main_input_dim: ä¸»è¦è¾“å…¥(HPNè¾“å‡º)
        :param main_output_dim: ä¸»è¦è¾“å‡º(HPNè¾“å‡º)
        :param  n_heads: å¤šå¤´
        
        :return [batch_size,main_input_dim, main_output_dim * self.n_heads]: 

        ä½¿ç”¨æ–¹æ³•
        forward
        '''
        super().__init__()
        self.main_input_dim = main_input_dim
        self.main_output_dim = main_output_dim
        self.output_dim = main_input_dim * main_output_dim
        self.activation_func_name = activation_func_name
        self.n_heads = n_heads
        self.use_bias = use_bias
        
        #è¶…ç½‘ç»œå±‚
        self.multihead_weight_nn = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            get_activation_func(self.activation_func_name, hidden_dim),
            nn.Linear(hidden_dim, self.output_dim * self.n_heads),
        )
        if self.use_bias == True:
            #åç½®å±‚
            self.multihead_bias_nn = nn.Sequential(
                nn.Linear(input_dim, hidden_dim),
                get_activation_func(self.activation_func_name, hidden_dim),
                nn.Linear(hidden_dim, self.main_output_dim * self.n_heads),
            )

    def forward(self, x):#[batch_size,main_input_dim * main_output_dim * self.n_heads]
        #->[batch_size,main_input_dim, main_output_dim * self.n_heads]
        weights = self.multihead_weight_nn(x).view([-1, self.main_input_dim, self.main_output_dim * self.n_heads])
        
        if self.use_bias == True:
            #->[batch_size, main_output_dim * n_heads]
            biases = self.multihead_bias_nn(x).view([-1, self.main_output_dim * self.n_heads])
            
            return weights, biases
        else:
            return weights
        
#2.GlobalçŠ¶æ€å¤„ç†å±‚-----------------------------------------------------------------------------------------------
class GlobalLayer(nn.Module):
    def __init__(self,output_dim):
        super().__init__()
        self.global_state_len = 30
        self.linear_layer, self.linear_layer_out_dim = linear_layer([None, self.global_state_len], output_dim) #64
    def forward(self, x):
        x = x.float()
        x = self.linear_layer(x)
        return x    
#3.SelfçŠ¶æ€å¤„ç†å±‚-------------------------------------------------------------------------------------------------
class SelfLayer(nn.Module):
    def __init__(self,output_dim,hidden_dim=None,embed_net=None):
        super().__init__()
        self.input_dim=16+8+6-3+73
        self.output_dim = output_dim
        self.hidden_dim = hidden_dim
        self.embed_net = embed_net if embed_net is not None else AgentEmbedding()
        self.own = nn.Linear(self.input_dim, self.output_dim, bias=True)
    
    def init_hidden(self):
        '''BUG:ğŸŸ ç›®å‰å°šæœªä½¿ç”¨éšè—å±‚
        
        '''
        return self.own.weight.new(1, self.rnn_hidden_dim).zero_()
    
    def forward(self,x):
        #(16             ,8           ,6           ,70      )
        my_character_type,my_role_type,my_buff_type,my_states = self.embed_net(x)
        input_tensor = torch.cat([my_character_type, my_role_type, my_buff_type,my_states], dim=1).float()
        output = self.own(input)
        return input_tensor,output #BUG:è¿™é‡Œéœ€è¦æŠŠæ™ºèƒ½ä½“çŠ¶æ€ç»™è¾“å‡ºäº†
        

#4.AgentçŠ¶æ€å¤„ç†å±‚------------------------------------------------------------------------------------------------
class AgentLayer(nn.Module):
    '''AgentçŠ¶æ€å¤„ç†
    :param embed_net :ä¸ºæ‰€æœ‰Agentä½¿ç”¨åŒä¸€ä¸ªåµŒå…¥å±‚è½¬æ¢ä¸ºç‰¹å¾å‘é‡
    :param hpn_net :ä¸ºæ‰€æœ‰Agentä½¿ç”¨åŒä¸€ä¸ªHPNå±‚æ¥ç”ŸæˆçŸ©é˜µ
        
    '''
    def __init__(self, output_dim, n_heads,
                 embed_net=None, hpn_net=None):
        super().__init__()
        #RNN
        self.output_dim = output_dim
        self.n_heads = n_heads

        #ä½¿ç”¨Embeddingå±‚
        self.embed_net = embed_net if embed_net is not None else AgentEmbedding()
        #ä½¿ç”¨HPNå±‚
        self.hpn_net = hpn_net if hpn_net is not None else Hypernet(
            input_dim=16+8+6-3+73,
            hidden_dim=256,
            main_input_dim=16+8+6-3+73,
            main_output_dim=output_dim,  # ç¡®ä¿ main_output_dim ä¸ output_dim ä¸€è‡´
            n_heads=n_heads,
            activation_func_name='relu'
        )

    def forward(self, x):
        #(16             ,8           ,6           ,70      )
        my_character_type,my_role_type,my_buff_type,my_states = self.embed_net(x)
        
        #(1)æ ¹æ®ç‰¹å¾ç”ŸæˆçŸ©é˜µæƒé‡
        #100
        hyper_input = torch.cat([my_character_type, my_role_type, my_buff_type,my_states], dim=1).float()
        
        #[6]->[batch_size,main_input_dim, main_output_dim * self.n_heads]
        input_w_agent, input_b_agent = self.hpn_net(hyper_input)
        
        #(2)è¿›è¡ŒçŸ©é˜µè¿ç®—
        #[batch_size,main_input_dim] * [batch_size,main_input_dim, main_output_dim * n_heads] ->[batch_size, n_heads, output_dim * n_heads]
        
        #output_agent = torch.matmul(matmul_input.unsqueeze(1), input_w_agent).squeeze(1)
        #output_agent += input_b_agent.unsqueeze(1)
        #output_agent = output_agent.view(-1, self.n_heads, self.output_dim)
        
        output_agent = torch.matmul(hyper_input.unsqueeze(1), input_w_agent)
        output_agent += input_b_agent
        output_agent = output_agent.view(
            -1, self.n_heads, self.output_dim #BUG:éœ€è¦ç¡®ä¿ main_output_dim = output_dimï¼Œå¦åˆ™è¿™ä¸ªé‡å¡‘ä¼šå‡ºé”™
        )#[batch_size,n_heads,output_dim]

        return output_agent
#4.----------------------------------------------------------------------------------------------

#=================================================================================================    
class HPNPolicy(nn.Module):
    def __init__(self,
                 hpn_hidden_dim,rnn_hidden_dim,
                 n_heads_input,n_heads_output):
        super().__init__()
        #å½¢çŠ¶ä¿¡æ¯
        self.hpn_hidden_dim = hpn_hidden_dim
        self.rnn_hidden_dim = rnn_hidden_dim if rnn_hidden_dim is not None else 128 #ğŸŸ BUG:ç„å­¦è°ƒå‚
        #BUG:ç»†åˆ†---------------------self.n_heads = n_heads #åˆ‡è®°ä¸å¯å¤ªé«˜ï¼Œå¦åˆ™....
        self.n_heads_input = n_heads_input #è¿™æ˜¯åˆå¹¶è¾“å…¥
        self.n_heads_output = n_heads_output #è¿™æ˜¯æŠ€èƒ½åŠ¨ä½œè¾“å‡ºçš„å¤šå¤´
        self.use_bias = True #æ˜¯outputä¸“æœ‰åŠ¨ä½œæ—¶å€™ä½¿ç”¨
        
        #(1)states_embeddingå±‚--æ‰€æœ‰äººå…±ç”¨ä¸€ä¸ª è½¬ä¸ºç‰¹å¾å‘é‡
        self.agent_embedding_net = AgentEmbedding()
        #actions_embeddingå±‚--ç”¨äºåˆå¹¶åŠ¨ä½œ
        self.action_embedding_net = ActionEmbedding(embedding_dim=128)

        #(2)HPNå±‚--ä¸€å…±æœ‰ä¸¤å¥—ç½‘ç»œ æ•Œäººå’Œé˜Ÿå‹
        self.hyper_input_w_ally = Hypernet( #100çš„è¾“å…¥å±‚ï¼Œ256çš„éšè—å±‚ï¼Œå¦‚æœoutput_dim=128ï¼Œåˆ™æœ€ç»ˆçš„è¶…ç½‘ç»œè¦è¾“å‡ºçš„æƒé‡é«˜è¾¾...
            input_dim=16+8+6-3+73,     #100*128*5=64000çš„è¾“å‡ºå±‚
            #ğŸŸ å†æé†’ä¸€æ¬¡ï¼Œ16+8+6-3+73=100ï¼Œä¸ºä»€ä¹ˆæ˜¯-3å·²ç»è§£é‡Šè¿‡äº†
            hidden_dim=self.hpn_hidden_dim,
            main_input_dim=16+8+6-3+73,
            main_output_dim= self.hpn_hidden_dim,  # ç¡®ä¿ hpn_hidden_dim ä¸ output_dim ä¸€è‡´
            n_heads= self.n_heads_input,
            activation_func_name='relu',
            use_bias = True
        )
        self.hyper_input_w_anemy = Hypernet( 
            input_dim=16+8+6-3+73,     
            hidden_dim=self.hpn_hidden_dim,
            main_input_dim=16+8+6-3+73,
            main_output_dim= self.hpn_hidden_dim,
            n_heads= self.n_heads_input,
            activation_func_name='relu',
            use_bias = True
        )
        
        #(3)åˆå¹¶å±‚--ç”¨äºåˆå¹¶HPNäº§ç”Ÿçš„å¤šå¤´
        #[bs, n_head, fea_dim]->[bs, fea_dim]
        self.unify_input_heads = Merger_1(self.n_heads_input, self.rnn_hidden_dim)
        #[batch_size, 1, n_heads, fea_dim]->[bs, fea_dim]
        self.unify_output_heads = Merger_2(self.n_heads_output, 52-12)
        #ğŸ‘†æ³¨æ„Merger_1å’ŒMerger_2æ˜¯å¤„ç†ä¸åŒç»´åº¦çš„åˆå¹¶ï¼Œå¦‚ä¸Šæ³¨é‡Šæ‰€ç¤º
        
        #(4)RNNå±‚
        #ä½¿ç”¨ nn.GRUCellå¤„ç†å•ä¸ªæ—¶é—´æ­¥é•¿çš„è¾“å…¥
        #
        self.rnn = nn.GRUCell(self.rnn_hidden_dim, self.rnn_hidden_dim)
        
        #A-å…¬æœ‰åŠ¨ä½œå±‚
        self.output_normal_actions = nn.Linear(self.rnn_hidden_dim, 12) 
        
        #B-ä¸“æœ‰æŠ€èƒ½å±‚
        self.hyper_output_w_action = Hypernet( 
            input_dim=16+8+6-3+73,    
            hidden_dim=self.hpn_hidden_dim,
            main_input_dim= self.rnn_hidden_dim,
            main_output_dim= 52-12, #åŠ¨ä½œç©ºé—´ä¸º52ï¼Œå…¶ä¸­å…¬æœ‰åŠ¨ä½œ12ä¸ªï¼Œä¸“æœ‰åŠ¨ä½œ40ä¸ª
            n_heads= self.n_heads_output,
            activation_func_name='relu',
            use_bias = False #ğŸŸ å†æ¬¡å¼ºè°ƒï¼Œè¿™é‡Œçš„use_biasæ˜¯Falseï¼Œæ„å‘³ç€åç½®æ˜¯ç”¨hyper_output_b_actionä¸“é—¨è®¡ç®—çš„
        )
        self.hyper_output_b_action = Hypernet( #ä¸“é—¨ç”¨æ¥è®¡ç®—åç½®
            input_dim=16+8+6-3+73,     
            hidden_dim=self.hpn_hidden_dim,
            main_input_dim= self.rnn_hidden_dim,
            main_output_dim= 52-12,
            n_heads= self.n_heads_output,
            activation_func_name='relu',
            use_bias = False #ğŸŸ è¿™é‡Œä¹Ÿæ˜¯False
        ) 
        
        #+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
        #(1)Globalå±‚
        self.global_state_layer = GlobalLayer(rnn_hidden_dim) #ç›´æ¥çº¿æ€§å±‚
        
        #(2)Selfå±‚ åˆ†ä¸ºcriticå’Œactorç½‘ç»œ
        self.self_state_layer = SelfLayer(rnn_hidden_dim)
        self.self_state_layer_2 = AgentLayer(rnn_hidden_dim,self.n_heads_input,
                                            self.agent_embedding_net,self.hyper_input_w_ally)

        #(3)allyå±‚ -- å…¶ä¸­æ²¡æœ‰æ–°å¢ä»»ä½•ç¥ç»ç½‘ç»œ-ç›¸å½“äºé›†æˆ
        self.ally0_state_layer = AgentLayer(rnn_hidden_dim,self.n_heads_input,
                                            self.agent_embedding_net,self.hyper_input_w_ally)
        self.ally1_state_layer = AgentLayer(rnn_hidden_dim,self.n_heads_input,
                                            self.agent_embedding_net,self.hyper_input_w_ally)

        #(4)enemyå±‚
        self.enemy0_state_layer = AgentLayer(rnn_hidden_dim,self.n_heads_input,
                                            self.agent_embedding_net, self.hyper_input_w_anemy)
        self.enemy1_state_layer = AgentLayer(rnn_hidden_dim,self.n_heads_input,
                                            self.agent_embedding_net, self.hyper_input_w_anemy)
        self.enemy2_state_layer = AgentLayer(rnn_hidden_dim,self.n_heads_input,
                                            self.agent_embedding_net, self.hyper_input_w_anemy)

        #+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

        #å®šä¹‰criticå±‚
        self.critic_input_dim  = 3 * self.rnn_hidden_dim
        self.critic_hidden_dim = 5 * self.rnn_hidden_dim
        self.critic_layer = nn.Sequential(
            nn.Linear(self.critic_input_dim, self.critic_hidden_dim ), 
            nn.ReLU(), 
            nn.Linear(self.critic_hidden_dim , 1), 
            nn.ReLU()
        )
        
        # å®šä¹‰ä¼˜åŒ–å™¨
        self.opt = optim.Adam(self.parameters(), lr=1e-3) #ğŸ”´å¦‚ä½•åˆå§‹åŒ–æ‰€æœ‰å‚æ•°?
    
    def forward(self,states,hidden_state):
        global_feature = states[0].float()
        self_feature = states[1]
        ally0_feature = states[2]
        ally1_feature = states[3]
        enemy0_feature = states[4]
        enemy1_feature = states[5]
        enemy2_feature = states[6]
        if len(states) > 7: #action_maskåŠ¨ä½œæ©ç 
            action_mask = states[7].float()
        
        #(1)Globalå±‚
        global_embedding = self.global_state_layer(global_feature)
        
        #(2)Selfå±‚ 
        self_feats, self_embedding = self.self_state_layer(self_feature)
        #ğŸ‘†è¿™é‡Œè¿”å›çš„self_featsæ˜¯ç”¨äºç»™self.hyper_output_w_actionçš„è¾“å…¥

        #(3)allyå±‚ 
        ally0_feature = self.ally0_state_layer(ally0_feature)
        ally1_feature = self.ally1_state_layer(ally1_feature)
        ally_embedding = self.unify_input_heads( 
            ally0_feature + ally1_feature
        )

        #(4)enemyå±‚
        enemy0_feature = self.enemy0_state_layer(enemy0_feature)
        enemy1_feature = self.enemy1_state_layer(enemy1_feature)
        enemy2_feature = self.enemy2_state_layer(enemy2_feature)
        enemy_embedding = self.unify_input_heads(
            enemy0_feature + enemy1_feature + enemy2_feature
        )

        #a.åˆå¹¶å±‚
        #BUG:æ­¤å¤„ä½¿ç”¨åŠ æ³•å±‚==========================================================================================
        embedding = global_embedding + self_embedding + ally_embedding + enemy_embedding
        
        self_embedding_2 = self.self_state_layer_2(self_feature)
        ally_embedding_2 = ally_embedding + self.unify_input_heads(self_embedding_2)
        embedding_critic = torch.cat([global_embedding,ally_embedding_2,enemy_embedding],dim = 1).float()

        #==============================================Actorç½‘ç»œ====================================================
        #b.æ¿€æ´»å’ŒRNN
        x = F.relu(embedding, inplace=True)
        h_in = hidden_state.reshape(-1, self.rnn_hidden_dim) #é¦–æ¬¡è¿è¡Œä½¿ç”¨é›¶çŠ¶æ€: h_in = torch.zeros(batch_size, rnn_hidden_dim)
        hh = self.rnn(x, h_in)  # [bs, rnn_hidden_dim]

        #c.è®¡ç®—å…¬æœ‰åŠ¨ä½œçš„ä»·å€¼
        q_normal = self.output_normal_actions(hh).view(-1, self.n_agents, 12)  # [bs, n_agents, 12]

        #d.è®¡ç®—ä¸“æœ‰åŠ¨ä½œä»·å€¼+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
        #Part1-ç”Ÿæˆæƒé‡
        # agent_featsä¸º[batch_size, agent_feature_dim]
        # åˆå§‹è¾“å‡º-> [batch_size, rnn_hidden_dim * 40 * n_heads]
        output_w_special = self.hyper_output_w_action(self_feats) #ğŸŸ åªè¿”å›ä¸€ä¸ªå¯¹è±¡
        
        #+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
        output_w_special = output_w_special.view(-1, 40 * self.n_heads_output, self.rnn_hidden_dim).transpose(1, 2)

        #Part2-ç”Ÿæˆåç½®
        output_b_special = self.hyper_output_b_action(self_feats).view( -1 ,40 * self.n_heads_output)  
        
        # Part3-è®¡ç®—Qå€¼------é€šè¿‡çŸ©é˜µä¹˜æ³•è®¡ç®—æ¯ä¸ªä¸“æœ‰åŠ¨ä½œçš„Qå€¼
        # [batch_size, 1, rnn_hidden_dim] * [batch_size, rnn_hidden_dim, 40 * n_heads] = [batch_size, 1, 40 * n_heads]
        #BUG:é”™è¯¯çš„q_valuesè®¡ç®—---------------------------------------------------------------------------
        q_values = torch.matmul(hh.unsqueeze(1), output_w_special) #BUG:hh.unsqueeze(1)??????

        if self.use_bias:
            # å¢åŠ ä¸€ä¸ªç»´åº¦ä½¿åç½®ä¸q_valuesçš„å½¢çŠ¶åŒ¹é…
            q_values += output_b_special.unsqueeze(1) #->[batch_size, 1, 40 * n_heads]
        
        #BUG:å¤šä½™çš„å¹³å‡å€¼åˆå¹¶--------------------------------------------------
        #-->[batch_size, 1, 40 * n_heads]->[batch_size, 1, 40, n_heads]
        #q_values_unified = q_values.view(-1, 1, 40, self.n_heads_output).mean(dim=-1)
        
        #ä½¿ç”¨å¤æ‚çš„æƒé‡çŸ©é˜µåˆå¹¶+++++++++++++++++++++++++++++++++++++++++++++++++
        #->[batch_size, 1, 40, n_heads]-->[batch_size, 40]
        q_values = self.unify_output_heads(q_values)
        # è¿™é‡Œéœ€è¦ç¡®ä¿ unify_output_heads æ–¹æ³•è¾“å‡ºæ­£ç¡®çš„å½¢çŠ¶

        
        q = torch.cat([q_normal,q_values],dim=-1)
        #è½¬ä¸ºæ¦‚ç‡
        #logits_p = F.softmax(q, dim=-1)

        #==============================================Criticç½‘ç»œ====================================================
        value = self.critic_layer(embedding_critic)
        
        if len(states) > 7:  # å¦‚æœæœ‰åŠ¨ä½œæ©ç 
            large_negative = torch.finfo(q.dtype).min if q.dtype == torch.float32 else -1e9
            # åº”ç”¨æ©ç ï¼Œæœªæ©ç çš„ä¿æŒåŸå€¼ï¼Œæ©ç çš„è®¾ç½®ä¸ºéå¸¸å°çš„å€¼
            mask_q = q * action_mask + (1 - action_mask) * large_negative
            # å¯¹è°ƒæ•´åçš„logitsåº”ç”¨softmaxï¼Œè½¬æ¢ä¸ºæ¦‚ç‡
            probs = nn.functional.softmax(mask_q, dim=-1)
            return value.float(), probs.float(), hh
        else:
            #BUG:å¦‚æœæ²¡æœ‰æ©ç ï¼Œç›´æ¥å¯¹åŸå§‹Qå€¼åº”ç”¨softmaxè½¬æ¢ä¸ºæ¦‚ç‡
            probs = nn.functional.softmax(q, dim=-1)
            return value.float(), probs.float(), hh
        

#=================================================================================================    
#
#
#
#=================================================================================================
#1.BCç¦»çº¿è®­ç»ƒç¯å¢ƒ
class TrainHPC(nn.Module):
    def __init__(self):
        pass
#==================================================================================================
